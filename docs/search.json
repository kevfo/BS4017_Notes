[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BS4017: High Throughput Bioinformatics",
    "section": "",
    "text": "This is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "chapters/week1.html",
    "href": "chapters/week1.html",
    "title": "1  Introduction to Linux and the Command Line (untested)",
    "section": "",
    "text": "This week’s lecture aims to cover the following topics:\nLike the title of chapter implies, the information presented in this chapter will not be tested."
  },
  {
    "objectID": "chapters/week1.html#a-brief-introduction-to-computers",
    "href": "chapters/week1.html#a-brief-introduction-to-computers",
    "title": "1  Introduction to Linux and the Command Line (untested)",
    "section": "1.1 A Brief Introduction to Computers",
    "text": "1.1 A Brief Introduction to Computers\n\n1.1.1 Turing’s Machine\n\n\n\n\n\nIllustration of a Turing Machine\n\n\n\n\nA universal machine is a machine that can solve any sequence of problems that can be solved using a computer. An machine is called Turing complete if it can act like a Turing machine: a machine that is capable of following certain rules to solve problems in a stepwise fashion. Many of today’s programming languages are Turing-complete.\n\n\n1.1.2 Machine Language\nMachine language is the only thing that computers understand.\nThe central processing unit (i.e., CPU) is the so-called “brain” of the computer and uses bits to work. When one talks about a “64-bit: CPU, it means the groups of bits are 64 in length.\nComputers understand instructions in a language made of bits, but it’s really tough for people to read and figure out what’s going on. So, to make it easier, an operating system (i.e., OS) is necessary. This is like a middleman that helps us talk to the computer in a way we can understand better."
  },
  {
    "objectID": "chapters/week1.html#unix-os",
    "href": "chapters/week1.html#unix-os",
    "title": "1  Introduction to Linux and the Command Line (untested)",
    "section": "1.2 Unix OS",
    "text": "1.2 Unix OS\nThe Uniplexed nformation and Computer Service (i.e., Unix for short) OS - often pronounced as “eunuchs” was created at Bell Laboratories in the early 1970s to help make software.\n\n\n\n\n\nPhotograph of Ken Thompson and Dennis Ritchie\n\n\n\n\nIn 1969, it started as a bunch of instructions written in a language computers understand, and it was made by Ken Thompson. Then, between 1972 and 1974, Ken Thompson and Dennis Ritchie made a new version using a language called “C”. Back then, anyone could look at and use the code for free.\nBut in the early 1980s, the company AT&T decided to keep the code secret and started selling licenses for using Unix. It even led to different versions of Unix being made by different companies.\nInterestingly, Mac OS X, the operating system used in Mac computers, is a type of Unix too!\n\n1.2.1 Unix Philosophy\nThe design idea behind Unix programs can be summarized into three bullet points:\n\nWrite programs that are really good at doing one thing.\nWrite programs that can team up and help one another out.\nWrite programs that are good at dealing with text, because text is one way that everyone can talk to one another.\n\nThe command line is also the key to using a Linux system.\nThere are also nine “paramount precepts” as Mike Gancarz summarizes:\n\nRemember, small things are nice.\nEach program should be awesome at doing just one thing.\nBuild a simple version first to test.\nIt’s better if your stuff works on lots of different computers.\nKeep your information in plain text files.\nUse existing software to help you do more.\nUse special scripts to make things even better and work on different computers.\nDon’t trap people in your program; let them do what they want.\nMake each program a tool to help with tasks."
  },
  {
    "objectID": "chapters/week1.html#linux-os",
    "href": "chapters/week1.html#linux-os",
    "title": "1  Introduction to Linux and the Command Line (untested)",
    "section": "1.3 Linux OS",
    "text": "1.3 Linux OS\n\n“I’m doing a (free) operating system (just a hobby, won’t be big and professional like gnu) for 386(486) AT clones.”\n– Linus Torvalds, August 25th, 1991.\n\nLinux is like a free operating system that works with Unix (i.e., older systems). When Unix started costing money in the 1980s, people wanted a free option. Linux is like the core part of a computer system (i.e., the kernel), connecting the software to the hardware and different programs to each other. To make it a complete system, it’s joined with other software, and this whole package is called a distribution.\n\n1.3.1 Why Use Linux?\nIt’s trustworthy and stays steady with fewer problems. There’s hardly any viruses to worry about. It’s quick because it’s built really well. Plus, Linux is free - the software is open, which means it works well with other things and gets better quickly.\nIf you want to make your own programs, it’s easy with Linux because there are free tools and helpful information. One can also change the Linux OS code if they want to.\n\n1.3.1.1 Why Use Linux for Bioinformatics Data Analysis?\nLinux has lots of little tools made by many people that can each do a small part of the work. One can mix these tools together to create pipelines that do big tasks.\nIt’s also a fantastic platform for open-source software, which means one can use many programming languages and libraries without paying.\nBut, keep in mind that using Linux might not be as easy as some other options. one’ll have to type commands on a special line, and it only does exactly what one tells it to, not what you might want it to do automatically."
  },
  {
    "objectID": "chapters/week1.html#bash-and-the-command-line",
    "href": "chapters/week1.html#bash-and-the-command-line",
    "title": "1  Introduction to Linux and the Command Line (untested)",
    "section": "1.4 Bash and the Command Line",
    "text": "1.4 Bash and the Command Line\n\n1.4.1 What is Bash?\nWhen one uses a computer with Unix, they can talk to it through something called a terminal emulator. This is a “window” to type things.\nThe terminal helps one use a special interface called a shell, which is like a way to talk to the computer by typing commands. There are different types of shells, but “bash” is the most common. It’s been around since 1989 and is used in systems like Linux and Apple’s OS X.\n\n\n1.4.2 The Command Line\nThe command line is a place where one types in what they want the computer to do. It’s not as easy as clicking on icons like in a Graphical User Interface (i.e., GUI), but it has its benefits.\n\n\n\n\n\nCommand Line Appearance After Logging into Singapore’s National Supercomputing Center\n\n\n\n\nIt’s a bit harder for beginners because they need to learn the right words (commands), but it’s faster and lets them do more. One can write down everything they do in a text file, which can be helpful. It’s also great for working with text and making the computer do things over and over automatically.\n\n1.4.2.1 Example: Connecting to a Remote Server Using an Encrypted SSH Protocol\nSecure shell (i.e., SSH) and secure copy (i.e., SCP) are like special ways to talk to a computer securely. They were made by someone named Tatu Ylönen in 1995.\n\n\n\n\n\nDiagrammatic Explanation of How SSH Works\n\n\n\n\nImagine one is sending secret messages over an unsecure network. SSH makes a safe pathway using a special key that has a lot of numbers. This key comes in two parts: the public key, which can be shared, and the private key, which keeps things secret.\n\n\n\n1.4.3 Basic Bash Operations\n\n1.4.3.1 Fundamental Operations\nSome basic commands include:\n\nls - this lists all files and folders in the current working directory.\ncd - this changes the working directory.\ncp - this makes a copy of a file.\n\nCommands also have something called flags that modify the output. For instance, ls -la lists all files (including the hidden ones) in the current working directory in long form.\nCommands also take in arguments to complete the command - for instance, cp file1 ../folder1.\nThe man command displays helpful information about a command - for instance, man ls will list information about the ls command.\n\n\n1.4.3.2 Bash Variables\nIn bash, one can use variables like containers for information.\nFor example, one can say A=1 to put the number 1 in a variable called A. When one wants to use that number, they can add a “$” before the variable’s name, like “$A”.\n\n\n\n\n\nExamples of Assigning and Displaying the Values of Bash Variables\n\n\n\n\nTo show the value of a variable on the screen, they can use echo and write echo $A. Some variables are made by the computer, like PATH, which tells the computer where to look for programs. One can also add their own places to look by changing PATH.\n\n\n1.4.3.3 Redirects\nWhen you one runs a regular Unix command, it shows words on the screen. However, one can make those words go somewhere else too.\nFor example, if they want to list files and save the list in a file, they can write ls > listfile.txt. If they want to add more files to that list, they can write ls >> listfile.txt.\nThey can also make the words go to another command by using a pipe, like ls | grep listfile.\nYou can do this as many times as you need.\n\n\n\n1.4.4 Linux File System\nIn Unix, there aren’t “hard drives” like we usually think of them. Instead, there are directories. Think of these as special folders. ’\n\n\n\n\n\nExample of a Linux File System\n\n\n\n\nWhen one connects to a hard drive, it’s divided into pieces, and each piece is attached to a directory. So, the directory shows what’s in that piece of the hard drive.\nWhen one uses the “mount” command, it links a special part of the hard drive or even something from another computer to a directory. This way, the directory shows the stuff from that hard drive or computer.\n\n\n1.4.5 Permission Management in Linux\nIn Unix, there are three groups for who can do what with files. The first is the user who owns the file - they can keep things private.\nThen there’s a bigger group of users who can share files. Finally, there’s others, which means everyone else. There are three types of things you can do with files:\n\nread (r)\nwrite (w)\nexecute (x)\n\nThese permissions are like rules for each group saying what they can and can’t do with the files.\n\n\n1.4.6 Bash as a Turing-Complete Language\nThe bash shell isn’t just about doing things; it’s like a language for telling the computer what to do. The programs you make using the Bash language are called shell scripts. These scripts are like lists of instructions that the computer understands.\nThey’re translated and done by the computer right away, which makes Bash an “interpreted” language. Shell scripts are really good for quickly working with text and doing powerful things. For example, at NSCC, they have a system where you put your special list (script) in a line and the computer runs it when it’s ready.\n\n\n1.4.7 Useful Pointers When Using Linux\nProf. Jarkko also lists some tips when using Linux to work on tasks:\n\nYou can’t easily get back deleted files.\nSmall and capital letters matter in commands and file names.\nSome characters like #;& ” / ’ : < > | * ? $ ( ) { } [ ] and space do special things.\nIt’s safest to use only letters, numbers, _ (underscore), and . (dot) in file names.\nIf you use those special characters, put quotes around the name.\nFile names can be anything, like a mytext.txt file might not be text, but it’s good to follow conventions!"
  },
  {
    "objectID": "chapters/week1.html#how-does-programming-work",
    "href": "chapters/week1.html#how-does-programming-work",
    "title": "1  Introduction to Linux and the Command Line (untested)",
    "section": "1.5 How Does Programming Work?",
    "text": "1.5 How Does Programming Work?\n\n\n\n\n\nRelationships Between Levels of Programming Languages\n\n\n\n\nProgramming languages, like C/C++ and Visual Basic, or Python, R, and Matlab, use special tools to change the commands one writes into instructions the computer understands. These tools are like translators. Some languages use a compiler, which does the translation all at once, while others use an interpreter, which does it step by step.\n\n1.5.1 Compilers vs. Interpreters\nThere are two main ways to change one’s programming commands into computer language:\n\nCompiler:\nIt takes your list of commands (code) and changes it all into computer language at once. This gives one a file that they can run as a program. One can use it from the command line or through a nice interface.\nInterpreter:\nIt changes your commands into computer language one by one as they use them. They can give commands directly or run a list of them from a file called a script. This is like a set of instructions in a text file.\n\n\n\n1.5.2 Low versus High Level Languages\nLow-level programming languages are like really simple tools for computers. They only know how to do basic things, and they’re kind of like talking to the computer in its own language. They can work directly with memory and other computer parts. This makes them run really fast, but when one wants to do complex things, they have to write a lot of instructions, and it can be hard to find mistakes in their code.\nHigh-level programming languages are like using simpler words for computers. They’re farther away from the computer’s language, so they’re easier for people to understand. They work kind of like how humans talk, and they’re good for organizing things like objects. When one uses them, they can write less code because they can do complicated stuff in a simpler way. That’s why many people like using them for most things they create on computers."
  },
  {
    "objectID": "chapters/week2.html",
    "href": "chapters/week2.html",
    "title": "2  Genomic Sequencing and Databases",
    "section": "",
    "text": "Modern day genomic sequencing began with Sanger sequencing.\nSanger sequencing, created in 1977, is a method used to read the genetic code of living things. It’s like reading a very long sentence written in a language that cells use. This method can read up to 800 to 1000 ‘letters’ of this genetic sentence in one go. Think of it as reading a paragraph with 800 to 1000 words! And now, modern versions of this method can read 96 paragraphs all at once, making it faster and more efficient.\nStarting from 2004, progress in this field has been really fast. The first machinery that were used before that have become old-fashioned and aren’t used as much anymore."
  },
  {
    "objectID": "chapters/week2.html#sequencing-fundamentals",
    "href": "chapters/week2.html#sequencing-fundamentals",
    "title": "2  Genomic Sequencing and Databases",
    "section": "2.1 Sequencing Fundamentals",
    "text": "2.1 Sequencing Fundamentals\nThere are a few special words we need to know\n\nDepth\nThis is like how many times we read the same sentence in the book to be really sure we got it right.\nCoverage\nThis is like the average number of times we read different sentences in a part of the book.\nRead length\nThis is just how much of the book we can read at once. It’s like reading a long or short paragraph.\n\nWhen we’re reading this book, we want to make sure we cover every part equally, like giving the same attention to every page. This is called uniform coverage.\nThere are two main ways to read the book:\n\nOne way reads a lot of sentences quickly, but not all of them in detail.\nThe other way reads fewer sentences, but really understands them well.\n\nSo, you can choose to read a lot of the book or read less but really understand it deeply."
  },
  {
    "objectID": "chapters/week2.html#illumina-hiseq-and-novaseq",
    "href": "chapters/week2.html#illumina-hiseq-and-novaseq",
    "title": "2  Genomic Sequencing and Databases",
    "section": "2.2 Illumina HiSeq and NovaSeq",
    "text": "2.2 Illumina HiSeq and NovaSeq\n\n\n\n\n\nIllumina RNA Sequencing Machine Models\n\n\n\n\nCreating Illumina libraries is like preparing a special recipe for reading DNA.\nFirst, a long DNA strand and break it into smaller pieces. Then, the ends of these pieces are fixed to make them neat and ready. A special tail is then added to one end, like putting a ribbon on a gift.\nAfter that, tiny adapters, like bookends, are attached to both ends of the DNA pieces. This helps scientists to read them later. Only the right-sized pieces are desired, so any pieces that are too big or too small are removed.\nScientists make many copies of these DNA pieces so we have enough to read. Finally, they use a special machine to read the DNA letters one by one, just like flipping through the pages of a book really fast. This helps scientists learn about the DNA’s secrets and how it works!\n\n2.2.1 Typical Illumina Read Structure\n\n\n\n\n\nIllumina RNA Read Structures\n\n\n\n\nA usual Illumina read has the following structure:\n\nIllumina Forward\nImagine starting an exciting adventure book. The “Illumina Forward” is like the first page of the book, where the story begins. It’s the beginning point of our DNA reading journey.\nForward Target Primer\nThink of this like a special bookmark in the adventure book. It’s a tiny piece that helps find the exact spot to start reading about in the DNA. It’s like telling the story, “Hey, start reading right here!”\nTarget\nPicture this as a hidden treasure in the adventure story. The “target” is the part of the DNA that scientists really want to learn about. It’s like the exciting part of the story that holds a secret they’re curious about.\nReverse Target Primer\nJust like the “Forward Target Primer” helps scientists find the beginning, this is like another bookmark that helps scientists find the end of the part we’re interested in. It’s like saying, “Okay, stop reading here!”\nIllumina Reverse\nThis is like reaching the last page of a book. The Illumina Reverse marks the end of our reading journey for this section of DNA, letting scientists know that we’ve completed the sequence.\n\n\n\n2.2.2 Single End, Paired End, and Mate-Pairs\n\n\n\n\n\nExample of Mate Pair Construction to Construct a Full Genome\n\n\n\n\nIllumina is a method for reading DNA that’s like solving different puzzles. Imagine having pieces of a jigsaw puzzle.\nFirst, the scientist can look at just one side of each piece to see what’s there (i.e., single end). Or they can look at both sides of the pieces, but not the part in the middle (i.e., paired end). There’s also a special kind where they link bigger puzzle pieces together (i.e., mate-pair) to understand them better.\nIn the end, no matter which puzzle they choose, they get to read both sides and find out the average distance between them. These days, the most popular puzzle is the paired end, while the mate-pair puzzle is not used much.\nAlso, the smaller the puzzle piece, the harder it is to figure out where it fits in the bigger picture of the DNA. But having two sets of puzzle pieces helps scientists figure out where they go in the DNA picture more accurately.\n\n\n2.2.3 Barcoding\n\n\n\n\n\nExample of How a Barcode Can be Used\n\n\n\n\nIllumina sequencing can use something called **barcodes*&, which are like special tags added to each sequence. Think of them like labels on different books.\nImagine a library of books where and each book has a unique label. In the same way, the sequences get their own labels. If the labels are longer, it’s like having more specific tags for each book. This means you can put even more sequences together for reading, like having a huge shelf of books with similar tags.\nFor instance, a technology called 10x Genomics uses these longer labels to group sequences together, especially when looking at individual cells.\n\n\n2.2.4 FASTQ Formats\nIllumina returns data in a special text format called FASTQ. Imagine it’s like a recipe card for reading DNA. This card has four parts for each piece of DNA it reads:\n\nThe first part is like a name tag. It tells us which piece of DNA we’re looking at. Imagine it’s like a label on a box that says what’s inside.\nThe second part is the actual DNA sequence, like a secret code of letters (A, T, C, G, N). It’s like a coded message that we need to decode.\nThe third part is a repeat of the name tag. It’s like someone saying, “Hey, this is still the same box we talked about earlier.”\nThe fourth part is a set of quality codes. This helps us know how sure we are about each letter in the DNA sequence. It’s like having a confidence score for each letter.\n\nAnd these quality codes are kind of like a secret code too, but they’re similar to something called Phred. It’s like a scale that tells us how reliable each letter is in the DNA code, just like how we might trust different people’s opinions more or less.\n\n2.2.4.1 Phred Quality Scores\n\n\n\n\n\nPhred Score Meanings\n\n\n\n\nThe quality \\(Q\\) is calculated using the following formula:\n\\[\\begin{equation}\n  Q = -10\\log_{10}P\n\\end{equation}\\]\nThough, the scores are reported in something called ASCII to save space."
  },
  {
    "objectID": "chapters/week2.html#pacbio-sequencing",
    "href": "chapters/week2.html#pacbio-sequencing",
    "title": "2  Genomic Sequencing and Databases",
    "section": "2.3 PacBio Sequencing",
    "text": "2.3 PacBio Sequencing\nPacBio sequencing is a way to read DNA that’s like watching a movie frame by frame.\n\n\n\n\n\nHow PacBio Sequencing Works\n\n\n\n\nImagine a movie reel, but instead of film frames, there are DNA pieces. First, a special machine copies the DNA, making many identical pieces. These pieces are attached to a surface, like putting stickers on a wall.\nThen, a tiny camera watches as a machine adds one letter at a time to the DNA chain. It’s like watching someone write a story, but in DNA language. The machine records this process, and scientists can use it to figure out the DNA’s secrets. This method is special because it can read long pieces of DNA in one go, like reading long sentences without stopping.\n\n\n\n\n\nPacBio Sequencing Components\n\n\n\n\nPacBio sequencing works a bit like making a detailed copy of a story. The scientists start with a special DNA template called an SMRTbell. Imagine this template as the outline of the story. They put it on a surface and use a special machine to make copies of it. These copies are like drafts of the story. Then, a tiny helper called a “polymerase” comes in and reads the story, one letter at a time. It’s like reading the book aloud to remember every detail.\nBut here’s the cool part: the machine doesn’t just read the story once. It goes over it several times, each time reading a bit more. These shorter readings are called subreads. Think of them as reading a book chapter by chapter.\nNow, after all these readings, the scientists put everything together like a puzzle. It’s like taking all those drafts and arranging them to get the complete story. This final version is called a Circular Consensus Sequence, which is like having the perfect version of the story after making sure all the words are correct. This method helps us read long pieces of DNA with a high level of accuracy, just like getting the full story right.\n\n2.3.1 PacBio Read Formats\nWhen PacBio finishes reading DNA, it’s like recording a video of the process. This video is saved as a “.mov” file, kind of like how you save a video on your phone. But to understand the DNA story better, scientists need to do more things. They use special software called “SMRT Tools,” which PacBio made and shared with everyone. With this software, they can do different tasks, like taking off the starting and ending parts of the video (SMRT bell adapters), and pulling out the most important parts, which are like key scenes in the movie (Circular Consensus Reads / Subreads).\nOnce they’ve done all this, they can change the video into a different format, like turning a video into pictures or text. They do this to make it easier to work with. They can turn the video into a “.bam” file, which is like a fancy organizer for the pictures, or a “.fastq” file, which is like turning the video into words. All of this helps scientists understand DNA better and find out its secrets. You can learn more about this software and how it works on the PacBio website.\n\n\n2.3.2 HiFi Reads\n\n\n\n\n\nHow HiFi Sequencing Works\n\n\n\n\nThe newest thing from PacBio is called HiFi sequencing. It’s like reading a really long story in a special way. Imagine having a super-long book with chapters that are 20 pages long.\nHiFi sequencing reads these chapters many times and figures out the best version. It’s like asking different people to read the same chapter and then picking the one that’s most accurate. This helps us understand long sections of DNA really well."
  },
  {
    "objectID": "chapters/week2.html#oxford-nanopore",
    "href": "chapters/week2.html#oxford-nanopore",
    "title": "2  Genomic Sequencing and Databases",
    "section": "2.4 Oxford Nanopore",
    "text": "2.4 Oxford Nanopore\n\n\n\n\n\nHow Oxford Nanopore Sequencing Works\n\n\n\n\nOxford Nanopore technology is a different way to read DNA. Instead of taking pictures, it watches electric signals over time. Think of it like watching a graph that goes up and down. This graph is called a squiggle.\nThey save this squiggle in a special file format called fast5. This file not only keeps the squiggle but also the letters that the computer guessed from the squiggle. It’s like writing down both what the graph looks like and what the scientist thinks it means. With new software they’re making, they can even go back to the squiggle and try to guess the letters again to make sure they got them right. It’s like looking at the graph again and trying to understand it even better.\n\n2.4.1 Uses for Long DNA Reads\nUsing Oxford Nanopore technology for DNA reading has different strengths depending on how many times the DNA is read.\nWhen they read it a few times (i.e., low coverage), it’s like filling in the missing pieces of a jigsaw puzzle or adding more information to an already started story. They can use these extra details to make an existing puzzle more complete (gap-filling), make a short story longer and clearer (scaffolding a short read assembly), or combine different pieces from different puzzles into one big picture (hybrid assembly).\nBut when they read the DNA many, many times (high coverage), it’s like writing a whole new story from scratch. They don’t need any other clues because they have everything they need. This is called “De novo assembly,” where they put together a complete picture of the DNA just by using these long reads. It’s like creating a new jigsaw puzzle using only the pieces from one box."
  },
  {
    "objectID": "chapters/week2.html#ion-torrent",
    "href": "chapters/week2.html#ion-torrent",
    "title": "2  Genomic Sequencing and Databases",
    "section": "2.5 Ion Torrent",
    "text": "2.5 Ion Torrent\n\n\n\n\n\nA Graph Obtained from an Ion Torrent Machine\n\n\n\n\nIon Torrent sequencing is like a special tool that’s great for certain types of projects. When scientists need to read pieces of DNA that are a bit longer (around 400-600 letters), Ion Torrent is like a superhero.\nImagine reading a longer chapter of a book instead of just a few sentences. This is really helpful for projects like studying tiny living things called microbes that live in different places, like our bodies or the environment. These projects, called microbiome studies, benefit a lot from Ion Torrent because it helps scientists understand these tiny creatures in more detail."
  },
  {
    "objectID": "chapters/week2.html#bgiseq-and-mgiseq",
    "href": "chapters/week2.html#bgiseq-and-mgiseq",
    "title": "2  Genomic Sequencing and Databases",
    "section": "2.6 BGISEQ and MGISEQ",
    "text": "2.6 BGISEQ and MGISEQ\n\n\n\n\n\nNanoballs in BGISEQ and MGISEQ\n\n\n\n\nBGI, a genomics institute, created special machines for reading DNA. One of them is called BGISEQ-500, kind of like an older model. It reads two lines of DNA that are 100 letters long each, making a total of around 520 million letters. Then there’s a newer model, MGISEQ-2000. It can read two lines that are 200 letters each, for a total of about 1 trillion letters! These machines were made to compete with another popular DNA reader, Illumina. They were designed to be really affordable, making DNA reading cheaper for everyone. It’s like offering a lower-cost way to explore the secrets of genetics."
  },
  {
    "objectID": "chapters/week2.html#hi-c-chip-seq-10x-and-bisulfite-sequencing",
    "href": "chapters/week2.html#hi-c-chip-seq-10x-and-bisulfite-sequencing",
    "title": "2  Genomic Sequencing and Databases",
    "section": "2.7 Hi-C, ChiP-seq, 10x, and Bisulfite Sequencing",
    "text": "2.7 Hi-C, ChiP-seq, 10x, and Bisulfite Sequencing\nThere are various ways to investigate specific things about DNA, like its unique features. The main difference comes in how the DNA is prepared in the lab, but the actual reading part uses a common Illumina platform. Think of it like different ways to prepare a special dish using the same cooking equipment. No matter which method is used, they all provide a type of output file called “fastq,” which is like a document containing DNA information. However, the way this information is used can vary depending on the specific method employed.\n\n2.7.1 Hi-C\n\n\n\n\n\nHow Hi-C Sequencing Works\n\n\n\n\nHi-C sequencing is a technique that helps scientists understand how different parts of DNA are arranged in space. It’s like making a map of how different rooms in a house are connected.\n\n\n\n\n\nHi-C Data\n\n\n\n\nThey capture this information by studying how different parts of the DNA are close to each other. This technique gives them a picture of how far apart or near different parts of the DNA are along the entire chromosome. It’s like learning about the layout of a house by seeing which rooms are close to each other.\n\n\n2.7.2 10x Genomics\n\n\n\n\n\nHow 10x Genomics Works\n\n\n\n\nIn 10x Genomics technology, each individual piece of DNA is given a special code, like a secret badge. Think of it like giving every player in a game their own unique mark. This mark is created using tiny gel beads in a special mixture. It’s as if each player gets a distinct symbol, helping scientists keep track of different pieces of DNA while they’re doing their research.\n\n2.7.2.1 In Unicellular RNA Sequencing\n\n\n\n\n\n10x Genomics for RNA Sequencing\n\n\n\n\nWhen using 10x Genomics for single-cell RNA sequencing, there’s a twist in how it works. Instead of using big pieces of DNA, they focus on individual cells. Imagine each cell is like a small character in a story. They put one cell into each tiny gel bead, kind of like each character in their own small bubble. Inside these bubbles, the cell’s RNA, which is like its story, is turned into a special type of DNA called cDNA. This process is like translating the cell’s story into a new language. This way, scientists can study the stories of many individual cells all at once, and see how they’re different or similar.\n\n\n\n2.7.3 Bisulfite Sequencing\n\n\n\n\n\nHow Bisulfite Sequencing Works\n\n\n\n\nIn bisulfite sequencing, DNA is treated with a special chemical called bisulfite. This chemical changes some parts of the DNA. Imagine it’s like using a magic potion on a drawing. When applied to the DNA, bisulfite changes cytosine to uracil, but it doesn’t affect 5-methylcytosine. It’s like turning some parts of the drawing into a new color while leaving other parts the same. This helps scientists understand which parts of the DNA have certain molecules attached to them.\n\n\n2.7.4 Chromatin Immunoprecipitation\n\n\n\n\n\nHow ChIP Works\n\n\n\n\nChromatin immunoprecipitation (i.e., ChIP) is a method used to study how proteins interact with DNA. Think of it as a way to find out which proteins are hanging out with specific parts of DNA. Here’s how it works:\n\nFirst, scientists fix the proteins they’re interested in, like transcription factors, to the DNA using a special chemical called formaldehyde. Imagine it’s like gluing the proteins to certain parts of the DNA.\nThen they carefully take out the DNA and break it into smaller pieces, like breaking a long necklace into smaller beads.\nNext, they use special antibodies that act like magnets to pull out the proteins they’re studying. It’s like using a magnet to pick up certain toys from a pile.\nAfter that, they heat everything up to undo the gluing caused by formaldehyde. This step is like melting the glue and separating the proteins from the DNA.\n\nAs a result, they end up with DNA fragments that were connected to the proteins they were interested in. It’s like getting clues about which proteins were spending time with specific parts of the DNA. This helps scientists understand how different proteins control and interact with genes and DNA."
  },
  {
    "objectID": "chapters/week2.html#online-data-repositories-for-sequenced-data",
    "href": "chapters/week2.html#online-data-repositories-for-sequenced-data",
    "title": "2  Genomic Sequencing and Databases",
    "section": "2.8 Online Data Repositories for Sequenced Data",
    "text": "2.8 Online Data Repositories for Sequenced Data\n\n2.8.1 Sequence Read Archive (i.e., SRA)\nThe Sequence Read Archive (i.e., SRA) is like a big library where scientists from around the world store their DNA and RNA sequencing data. It’s kind of like a safe place for important information. This repository is taken care of by a group called NIH, in the USA.\nInside the SRA, you’ll find the raw data from sequencing, which is like the original puzzle pieces of DNA or RNA. Think of it as the untouched information from which scientists make discoveries. Both DNA and RNA data are kept here, like storing books of different kinds in the same library.\nMany scientific journals require researchers to share their sequencing data in the SRA. This is important because it allows other scientists to check their work and try things out for themselves. It’s like sharing a recipe so others can cook the same dish. Anyone can download this data for free, helping scientists all over the world learn from each other. However, more detailed information like complete genomes and detailed explanations are stored somewhere else. Sometimes scientists need to process the raw data a bit more to make sense of it, like cooking the raw ingredients into a delicious meal.\n\n\n2.8.2 NCBI Genomes\n\n\n\n\n\nNCBI Genomes\n\n\n\n\nThe NCBI Genomes database is like a huge book that holds a lot of important details about different species. It not only tells you what species a living thing belongs to, but it also lets you know if its DNA has been fully read and studied.\nInside this database, you’ll find information about the species’ classification, kind of like its scientific family tree. It’s like knowing which branch of the animal kingdom it belongs to. Additionally, you can find out if the species’ DNA has been completely read and studied in-depth.\nHowever, this database usually contains only the main or reference version of the species’ DNA, and it comes with annotations that tell you where different genes are located. These annotations are stored in a special kind of file called a “.gff” file, which is like a map showing where different treasures (genes) are hidden in the DNA. So, this database is like a treasure trove of genetic information about different species, helping scientists and researchers understand their DNA better.\n\n\n2.8.3 EBI: Ensembl Project\n\n\n\n\n\nEnsembl Project Homepage\n\n\n\n\nThe EBI’s Ensembl Project is like a special tool that helps scientists explore and understand the DNA of different living things. It’s kind of like a map for navigating the genetic information of various species.\nThis project offers a genome browser that allows researchers to access annotated genomes of species that belong to specific groups in the animal kingdom. There are different sections, like Ensemble Bacteria, Protists, Fungi, Plants, Metazoa, and Vertebrates. It’s like having different shelves in a library for different types of books.\nFor each species in Ensembl, you’ll find at least the main version of its DNA and information about its genes. Think of it as knowing the basic story of each species. But sometimes, there’s even more information available, like extra chapters in a book. This project is a helpful tool for scientists to study and learn more about the genetics of various living things."
  },
  {
    "objectID": "chapters/week3.html",
    "href": "chapters/week3.html",
    "title": "3  Data Preprocessing and Quality Control",
    "section": "",
    "text": "Today’s discussion covers several important aspects of sequencing data analysis. First, it’s crucial to be aware of potential sources of errors that can occur during the sequencing process. Next, we’ll delve into preprocessing, which involves getting the raw sequencing data ready for analysis. Quality control measures will help ensure that the data is accurate and reliable. We’ll also explore methods for detecting contamination in the sequencing data. To put these concepts into practice, we’ll walk through an example analysis using Drosera capensis as our model organism."
  },
  {
    "objectID": "chapters/week3.html#sources-of-error-in-sequencing",
    "href": "chapters/week3.html#sources-of-error-in-sequencing",
    "title": "3  Data Preprocessing and Quality Control",
    "section": "3.1 Sources of Error in Sequencing",
    "text": "3.1 Sources of Error in Sequencing\n\n“Limitations of the sequencing platforms, and particular artifacts associated with sequences generated on these platforms, need to be understood and dealt with at various stages of the project including planning, sample preparation, run processing and downstream analyses.”\n– Addressing Challenges in the Production and Analysis of Illumina Sequencing Data\n\nData preprocessing and quality control are the two most important things in data analysis.\n\n\n\n\n\nSome Possible Errors During Sequencing\n\n\n\n\nThere’s a phrase called “garbage in, garbage out” or GIGO for short. What this basically means is that if you start with bad data, you will produce bad analysis. Similarly, if you start with poor-quality ingredients, you will not make good food. Because of this, you need to ensure that your data is workable before you do anything else.\n\n3.1.1 Problems with Sampling\nThe sample itself can introduce errors.\nFor instance, if you don’t know what you’re sampling or got your samples mixed up, this could influence the final results.\nOr, if your sample is contaminated or degraded (i.e., not taken care of well enough), this can also affect the final quality of the data.\n\n3.1.1.1 Possible Sources of Contamination\nThere are a few possible ones:\n\nMicrobes such as bacteria, viruses, parasites, and whatnot.\nMaybe the sampler themselves could have dirty hands and introduced something into the sample without knowing it?\nResearchers mixing their samples.\nUsing dirty tools.\n\nThere are more sources here.\n\n\n3.1.1.2 DNA Fragmentation\nThe environment can have a significant impact on ancient DNA samples. This degradation process causes the DNA to break into small fragments and leads to specific changes, such as the conversion of cytosines to uracil.\nTo tackle these challenges, scientists use various techniques to enrich fragments with uracils in ancient DNA samples. By analyzing the patterns of DNA fragmentation, researchers can clean and correct data, using tools like mapDamage. These methods help us make sense of ancient DNA, even when it’s been affected by the passage of time and environmental factors.\n\n\n\n3.1.2 Problems with Creating a Genomic Library\nThere are a few:\n\nAdapter Dimers\n\n\n\n\n\nIllustration of an Adapter Dimer\n\n\n\n\nAdapter dimers can reduce the amount of useful data that’s generated by the sequencing machine. An adapter dimer is a small bit of DNA that is mistakenly sequenced instead of the target DNA, so this decreases the amount of useful data at the end of the day.\nChimeras\n\n\n\n\n\nIllustration of two Chimeras\n\n\n\n\nA chimera is a DNA sequence that is artificially made by joining two more DNA sequences. This happens when adapters mistakenly link unrelated DNA fragments (i.e., especially the SMRTbell templates above).\nBad Insert Size\n\n\n\n\n\nIllustration of a Bad Insert Size\n\n\n\n\nThis refers to a badly-spaced gap between the DNA fragments at the end (i.e., the primers and adapters). The insert size - the “gap” - needs to be the right size.\nIf the insert size is too big or too small, this can lead to issues down the road.\nSequencing Artefacts\n\n\n\n\n\nExamples of Sequencing Artefacts\n\n\n\n\nA sequencing artefact is a fancy term to refer to anything during the sequencing process that can affect the final quality of the data - for instance, air bubbles and dust particles. These artefacts can lead to repetitive patterns.\nA common kind of artefact that occurs is when two DNA fragments produces two distinct clusters, hence affecting data analysis.\nDuplicated Reads\n\n\n\n\n\nExamples of Duplicated Reads\n\n\n\n\nThis refers to multiple copies of the same DNA sequence, and this can happen because of numerous factors.\nDuplicated Reads\n\n\n\n\n\nPlot Illustrating GC Content\n\n\n\n\nThis kind of bias happens in Illumina sequencing as the technology favors DNA sequences with different amounts of “G” and “C” nucleotides. This can lead to the uneven coverage of the genome. Furthermore, sequencing technologies like PacBio and Illumina don’t do well with long sequences of repeating DNA sequences.\nAt least PacBio is less error prone to GC content biases or DNA length. But, it does have a higher error rate (i.e., 13% - 15%) compared to other technologies."
  },
  {
    "objectID": "chapters/week3.html#preprocessing-techniques",
    "href": "chapters/week3.html#preprocessing-techniques",
    "title": "3  Data Preprocessing and Quality Control",
    "section": "3.2 Preprocessing Techniques",
    "text": "3.2 Preprocessing Techniques\n\n\n\n\n\nGeneral Workflow for Bioinformatics Pipelines\n\n\n\n\nThe above figure show general steps when it comes to working with raw data (i.e., .fq files).\n\n3.2.1 Adapter Removal\n\n\n\n\n\nIllustration of Adapter Removal\n\n\n\n\nAdapter removal refers to removing adapter sequences - short pieces of DNA used during sequencing. This step ensures that the data is as clean as possible.\n\n\n\n\n\nExamples of Adapters\n\n\n\n\nAdapters have specific sequences; software is designed to recognize, locate, and remove these adapters from the data.\nThese software can also handle some errors within the data and ensure that the adapters are removed from the data."
  },
  {
    "objectID": "chapters/week3.html#quality-control-with-fast-qc",
    "href": "chapters/week3.html#quality-control-with-fast-qc",
    "title": "3  Data Preprocessing and Quality Control",
    "section": "3.3 Quality Control with Fast QC",
    "text": "3.3 Quality Control with Fast QC\n\n3.3.1 FastQC\nThere are numerous statistics (by section name) to take note of when using FastQC to quality control data:\n\nBasic Statistics\n\n\n\n\n\nBasic Information in a FastQC Report\n\n\n\n\nThis part lists basic information about a raw data file.\nPer Base Sequence Quality\n\n\n\n\n\nQuality Scores Boxplot\n\n\n\n\nGenerally speaking, the longer the read, the lower the phred quality score.\nIn the above graph, we see that most boxplots have a median score of above 30, but there are also many whose minimum score (i.e., the bottom whisker) is below 20.\nPer Tile Sequence Quality\n\n\n\n\n\nQuality Scores Heatmap\n\n\n\n\nA blue square on this plot means that everything went well. Otherwise, the yellow, green, and red squares hint that there’s some issue with the quality of the data at that exact spot in the raw data.\nThe Y-axis is the phred score, but scaled up by 1000.\nPer Sequence Quality Scores\n\n\n\n\n\nQuality Scores Heatmap\n\n\n\n\nA blue square on this plot means that everything went well. Otherwise, the yellow, green, and red squares hint that there’s some issue with the quality of the data at that exact spot in the raw data.\nThe Y-axis is the phred score, but scaled up by 1000.\nPer Sequence Quality Scores\n\n\n\n\n\nPer Sequence Quality Plot\n\n\n\n\nThe Y-axis refers to the amount of DNA sequences that have that same mean phred score on the X-axis. That peak in the above density plot is the mean phred score of all DNA sequences.\nPer Sequence Quality Scores\n\n\n\n\n\nPer Sequence GC Content\n\n\n\n\nThis plot shows the percentages of bases along DNA sequencing reads.\nPer Sequence Quality Scores\n\n\n\n\n\nPer Base Sequence Content\n\n\n\n\nThis plot shows the percentages of bases along DNA sequencing reads.\nPer Base Sequence N Content\n\n\n\n\n\nPer Base Sequence N Content\n\n\n\n\nPer Base Sequence N Content\n\n\n\n\n\nPer Base Sequence N Content\n\n\n\n\nPer Base Sequence N Content\n\n\n\n\n\nSequence Duplication Levels"
  },
  {
    "objectID": "chapters/week3.html#identifying-possible-contaminations",
    "href": "chapters/week3.html#identifying-possible-contaminations",
    "title": "3  Data Preprocessing and Quality Control",
    "section": "3.4 Identifying Possible Contaminations",
    "text": "3.4 Identifying Possible Contaminations\n\n\n\n\n\nA Bimodal Distribution in a Set of Raw Data’s GC Content Distribution\n\n\n\n\nThe bimodal distribution in the GC count read (i.e., that red density plot) is an indicator of possible contamination. One of the peaks could be indicative of something else.\n\n3.4.1 Using Databases to Identify Possibly Contaminated Data\nOne can match part of their data against reference databases - this is usually done with tools like BLAST or Diamond as they readily do this for you.\nWhat follows after is something called metagenomics analysis - the goal of this kind of analysis is to determine the origin of the DNA sequences. The National Center for Biotechnology Information (i.e., NCBI) has a lot of DNA sequences and each sequence belongs to a species; there’s also a taxonomy tree that organizes these species into families, genuses, and species.\n\n3.4.1.1 How Does it Work?\nWhen comparing sequences against reference ones, we look for matches - these are called hits. Each DNA sequence or read that we compare is tied to a specific organism.\nTo classify these reads, we identify something called the lowest common ancestor (i.e, LCA) in the species tree for each read. What this basically means is that we find the most specific taxonomic level where all the species that our read matches have similar DNA. Because of this, each read that we compare has a taxonomic classification as well.\nTools such as MEGAN can help automate this process.\n\n\n\n\n\nExample Approach to Identify Contaminated Sequences\n\n\n\n\nThe species that are closer (at least from an evolutionary viewpoint) tend to get more hits in this example. If the species that was sequenced isn’t in the NCBI, then the BLAST that was run on other species would contain the sequence.\n\n\n\n3.4.2 Using K-mers to Identify Contamination\n\n\n\n\n\nExample on How to Use K-Mers to Identify Outliers\n\n\n\n\nA k-mer is a fixed DNA fragment of length “k”. The above graphic shows how one can use K-mers to identify contaminated samples:\n\nGiven a the genome (from NCBI) of a particular species, split it into k-mers and then find the LCA of that k-mer.\nWe’ll also split our read into the same k-mers.\nWe find hits between the k-mers from our hits and the k-mers from the species’ genomes. We can then apply some sort of voting system to classify the read."
  },
  {
    "objectID": "chapters/week3.html#is-there-enough-data",
    "href": "chapters/week3.html#is-there-enough-data",
    "title": "3  Data Preprocessing and Quality Control",
    "section": "3.5 Is There Enough Data?",
    "text": "3.5 Is There Enough Data?\nIn order to do something called de novo assembly, we need to know if there’s enough data first. We can do this through flow-cytometry based size estimates to get a rough idea of a genome’s size.\nBut, one thing to keep in mind is that different individuals in the species may have different genetic makeups and also different genome sizes (e.g., chromosomal abnormalities).\nA polyploid is an organism that has multiple sets of chromosomes, and they are more common than we may think.\n\n3.5.1 K-mer Histogram\n\n\n\n\n\nExample of a K-mer Histogram\n\n\n\n\nThe K-mers that we get from our reads can be made into a histogram. We basically just count how many times each k-mer appears in the read and make it into a histogram.\n\n\n\n\n\nDetermining Genome Size from a K-mer Histogram\n\n\n\n\nIf the k-mers that are used to make the histogram are long enough, the mode - the peak with the highest - is the most abundant k-mer in the data.\nWe also use the k-mer histogram’s mode to estimate of the coverage: the average amount of times that a base in the genome is sequenced.\nThen, we divide the total amount k-mers that have been sequenced by the said mode - this should give an estimate of the genome size.\n\n\n\n\n\nA K-mer Histogram with no Mode\n\n\n\n\nIf a K-mer histogram doesn’t have any modes (like the one above), this means that the coverage isn’t high enough. So, we need to add in more data; this is because the genome is too big.\n\n\n3.5.2 Estimating the “K” in K-mers\nIf the K-mer is pretty short - say, \\(K = 4\\), then the possible K-mers that could appear will appear. In this case, there are \\(4^4 = 256\\) different combinations of 4-mers. Though, one thing to be wary of is that short K-mers don’t have uniqueness because they can occur in so many places in the data.\nThe last point is in contrast to long K-mers - the longer the K-mer, the lesser the amount of K-mers possible for that amount of \\(K\\).\n\n\n\n\n\nHypothetical Versus Observed NUmber of K-Mers\n\n\n\n\nBecause of the above points, the number of unique K-mers in our data should make a sort of parabola, and that peak in the middle is our optimal \\(K\\) value.\n\n\n3.5.3 Kmergenie\n\n\n\n\n\nExample Output of Kmergenie\n\n\n\n\nKmergenie is a kind of software that helps people estimate the genome size of their data using the k-mer analysis (i.e., the points said before this). Though, some software like MaSuRCA require the user to specify a “k” value beforehand.\nThere is also another software called jellyfish that also does the same thing as kmergenie - it helps find the optimal value of \\(K\\) in the K-mer histogram.\nAnd then there’s also another piece of software called SPAdes - this uses multiple K-mer values and usually gives good results. SPAdes pretty much gives the user the option to choose from several optimal values of \\(K\\) given their goals."
  },
  {
    "objectID": "chapters/week3.html#data-driven-quality-control",
    "href": "chapters/week3.html#data-driven-quality-control",
    "title": "3  Data Preprocessing and Quality Control",
    "section": "3.6 Data-Driven Quality Control",
    "text": "3.6 Data-Driven Quality Control\nWe need to conduct a check on the data to assess its quality - this sort of checking can highlight any issues with a specific library or a dataset (though, the common errors may include stuff like contaminated adaptors, low-quality data, and sequencing errors).\nThat said, there are usually two parts to this “checking”:\n\nTrim Reads\nWe need to “trim” or remove any low-quality data or bases from the data. This helps improve the quality of the data (obviously).\nMapping to Reference Genome\nThis allows us to understand how well our data maps to the expected results.\n\nThen, once all of this is done, we need to find any outliers using Data Science techniques. These anomalies could mean that there’s a sequencing problem, sample contamination, or even some other issue that needs to be looked into.\n\n3.6.1 Making a New Genome\n\n\n\n\n\nExample Genome Assembled\n\n\n\n\nIf we make a new genome, we usually do something called a quick draft assembly on it. This can let us know stuff like coverage and insert size distribution and can be helpful down the road.\nThat said, there are two terms that are must-knows:\n\nContigs\nThis just refers to a contiguous DNA sequence that doesn’t have any gaps or unsequenced regions. These “contigs” represent continuous segments of the genome and are usually obtained in the early stages of the assembly process.\nScaffold\nThis is a long structure that you get from joining multiple contigs together. Here, contigs are joined using “N”s - unsequenced bases. Scaffolds help link contigs and are a more comprehensive representation of the genome.\n\n\n\n3.6.2 GC and Average Coverage Plot\nDifferent species have varying genome lengths and GC percentages. These characteristics are unique to each species and can significantly impact analysis.\nDuring the sequencing process, reads are randomly sampled from the genomes being studied. This random sampling can lead to one of two thigns:\n\nSpecies with long genomes tend to have lower average coverage because there are more DNA base pairs to cover with the same number of sequenced reads.\nSpecies with shorter genomes tend to have higher average coverage with the same sequencing depth.\n\nThat said, the GC content of a genome can vary based on various factors, including the species’ lifestyle, environmental niche, and energy source. Different species may have distinct GC percentages."
  },
  {
    "objectID": "chapters/week4.html",
    "href": "chapters/week4.html",
    "title": "4  De Novo Sequencing",
    "section": "",
    "text": "General Bioinformatics Workflow\nTools such as MaSurCA (which will be used during the practical) are used to make genomes from raw data after the data has had its primers (from earlier Illumina sequencing) removed. Then, we use tools like quast to perform quality control on it.\nThat said, the main point of an assembly is shown in the picture above. Given a ton of overlapping DNA sequences, we want to try to reconstruct the actual genome - like putting together puzzle pieces to make a puzzle1."
  },
  {
    "objectID": "chapters/week4.html#laws-of-assembly",
    "href": "chapters/week4.html#laws-of-assembly",
    "title": "4  De Novo Sequencing",
    "section": "4.1 Laws of Assembly",
    "text": "4.1 Laws of Assembly\nThere are two main laws:\n\nFirst Law\n\n\n\n\n\nFirst Law of Genome Assembly\n\n\n\n\nLet’s say that we have two different reads (i.e., sequences) in our raw data: “A” and “B”. If the last few letters of “A” are similar to the beginning letters of “B”, then we can guess that “A” and “B” probably overlap with one another in the actual genome.\nSecond Law\n\n\n\n\n\nSecond Law of Genome Assembly\n\n\n\n\nLet’s say that we have a whole bunch of reads in our raw data. If these reads have a higher coverage (i.e., they’re read many times), then we will have more overlaps in our final genome.\nThird Law\n\n\n\n\n\nThird Law of Genome Assembly\n\n\n\n\nHow long our reads are and how repetitive those patterns are in the genome can make genome assembly challenging.\nSo, the best thing to do in this scenario is to just get a long read that cover(s) the entire repetitive sequence(s).\n\n\n\n\n\nOutcomes of Different Resolving Approaches\n\n\n\n\nDepending on how we choose to go about this issue, we can get different results. Because of this, we tend to just handle repeats that cannot be resolved by leaving them out altogether. But, we must keep in mind that if we do do this, then our assembly will be in fragments or contigs for short.\n\nHence, in de novo assembly, our ultimate goal is to really just find overlapping, short reads and put them into longer, continuous DNA sequences (i.e., like piecing together a puzzle from scratch). We use two different approaches for the most part:\n\nShortest Common Substring (i.e., SCS)\nOverlap Layout Concensus\nde Brujin Graphs\n\nBut regardless of which of the above that we end up doing in the end, one thing’s for certain: we use graph theory for all of these methods!"
  },
  {
    "objectID": "chapters/week4.html#overlap-graphs",
    "href": "chapters/week4.html#overlap-graphs",
    "title": "4  De Novo Sequencing",
    "section": "4.2 Overlap Graphs",
    "text": "4.2 Overlap Graphs\nThere are two main terminologies to know when it comes to graphs.\n\nNode\nThis just means a “read” or a “k-mer” in the raw data.\nEdge\nThis is a line connecting two nodes. If this line is an “arrow”, then we say that this edge is directed.\n\n\n\n\n\n\nExample of an Overlap Graph\n\n\n\n\nIn the above graph (i.e., an example), the graph represents the 6-mers of the DNA sequence: GTACGTACGAT. For simplicity’s sake, we only draw directed edges (i.e., the arrows) between nodes (i.e., the k-mers); the weight or number above the edge shows how many letters each k-mer overlaps with the other.\n\n4.2.1 Hamiltonian Paths\n\n\n\n\n\nExample of a Hamiltonian Path in a 6-mer Graph\n\n\n\n\nWe say that a graph is Hamiltonian if and only if we can visit all of its nodes at least once. In this same example, if we try to overlap the different K-mers to form the sequence GTACGTACGAT, we see the path that this sequence takes in the graph visits the 6-mers at least once!"
  },
  {
    "objectID": "chapters/week4.html#shortest-common-substring-i.e.-scs",
    "href": "chapters/week4.html#shortest-common-substring-i.e.-scs",
    "title": "4  De Novo Sequencing",
    "section": "4.3 Shortest Common Substring (i.e., SCS)",
    "text": "4.3 Shortest Common Substring (i.e., SCS)\n\n\n\n\n\nIllustration of the Shortest Common Substring Problem\n\n\n\n\nHere’s how this works in a nutshell:\n\nWe are given a whole bunch of K-mers.\nWe then smoosh all of these k-mers together to form one big, long string.\nOur job is to then find the shortest substring of that “big, long string” that contains the original k-mers as substrings. This “shortest substring” is called the shortest common substring (i.e., SCS).\n\nProf. Jarkko mentions that finding the SCS is NP complete: what this basically means is that the longer the “big, long string”, the more exponential the time to find the SCS becomes (hence making it all the more challenging).\n\n4.3.1 Greedy SCS Algorithm\n\n\n\n\n\nIllustration of the Greedy Shortest Common Substring Problem\n\n\n\n\nIf an algorithm is greedy, this basically means that it aims to maximize something about it.\n\n\n\n\n\nSecond Illustration of the Greedy Shortest Common Substring Problem\n\n\n\n\nIn this greedy SCS problem, we first start with the overlap graphs for the k-mers. Then, we combine the k-mers based on the weights of their edges until we get the substring (taking to get rid of the overlaps in the process).\n\n\n\n\n\nIllustration of the Greedy SCS Gone Awry\n\n\n\n\nHowever, just because an algorithm is greedy doesn’t always mean that it will lead to the best (i.e., optimal) outcome. If we look at the 6-mers of the overlap graph of the string a_long_long_long_time and try to do the greedy SCS problem for it, we see that we just end up with a_long_long_time. This isn’t the same string!\nInterestingly enough, if we use k-mers with \\(k = 8\\), we see that the final string that’s formed is actually correct."
  },
  {
    "objectID": "chapters/week4.html#overlap-layout-consensus-i.e.-olc",
    "href": "chapters/week4.html#overlap-layout-consensus-i.e.-olc",
    "title": "4  De Novo Sequencing",
    "section": "4.4 Overlap Layout Consensus (i.e., OLC)",
    "text": "4.4 Overlap Layout Consensus (i.e., OLC)\n\n\n\n\n\nIllustration of the OLC Process\n\n\n\n\nThe above graphic summarizes the steps involved in OLC.\n\n4.4.1 Overlap\n\n\n\n\n\nIllustration of an Overlap\n\n\n\n\nAn overlap refers to the ending of a string having at least a certain amount of matches with the beginning of another string. In the above example, we have two strings “X” and “Y”.\nIf we say that we want at least three matches, we start from the beginning of “Y” and see that the sequence “TAG” is found in the middle of “X” - the same could more or less be said for “GCC” too.\n\n4.4.1.1 Layout of the Overlap Graph\n\n\n\n\n\nIllustration of the Overlap Graph for 7-Mers of to_every_thing_turn_turn_turn_there_is_a_season\n\n\n\n\nThe above layout graph is super unruly and needs to be simplified.\n\n\n\n\n\nSimplifying the Overlap Graph\n\n\n\n\nSo, the first thing we need to do is to just simplify this graph. If we take a closer look at the original graph, we see that some edges can be inferred from other edges - in this case, the green arrows can be inferred from the blue ones.\n\n\n\n\n\nFurther Simplification of the Overlap Graph\n\n\n\n\nWe then remove these green edges - first, the ones that skip a node, and then next, the ones that skip two or more nodes.\n\n\n\n\n\nUnresolvable Repeats\n\n\n\n\nHowever, we see that the stuff in the red box cannot be resolved further.\n\n\n\n\n\nHaploid Assembly of a Genome\n\n\n\n\nSo, what scientists do is to get the contigs, line them up, and take the majority vote of the sequences. So, for example, if one nucleotide has mostly “A”s in a spot, then scientists assume that that particular nucleotide in space is an “A”.\n\n\n4.4.1.2 Caution\nThis entire process (i.e., the one in the preceding sub-sub-subsection) is super slow, especially when you realize that many sequencing datasets have hundreds of millions or billions of reads.\nAnd even if you could make the overlap graph, the graph would be ginormous!"
  },
  {
    "objectID": "chapters/week4.html#de-brujin-graphs",
    "href": "chapters/week4.html#de-brujin-graphs",
    "title": "4  De Novo Sequencing",
    "section": "4.5 De Brujin Graphs",
    "text": "4.5 De Brujin Graphs\n\n\n\n\n\nDe Brujin Graph for the String tomorrow and tomorrow and tomorrow\n\n\n\n\nThe meaning of an edge hasn’t changed here, but there are new temrs to know:\n\nMultigraph\nThis is a graph that has more than one node coming into a node.\nIndegree\nThis refers to the amount of arrows (i.e., directed edges) coming into a node.\nOutdegree\nThis refers to the amount of arrows (i.e., directed edges) coming out of a node.\nBalanced nodes\nThe indegree and the outdegree of a node are the same.\nSemi-balanced node\nThe indegree differs by the outdegree of the node by one.\nConnected graph\nThis just means that all nodes in a graph can be reached by some other node.\n\nAs a super short trick, if a directed graph (i.e., graph with arrows for edges) has two semi-balanced nodes at the very most, then that graph is Eulerian.\n\n\n\n\n\nDe Brujin Graph for AAABBBBA\n\n\n\n\nFirst, we split the genome AAABBBBA into 3-mers before splitting the 3-mers into 2-mers.\n\n4.5.1 Eulerian Walks\n\n\n\n\n\nEulerian Walk in the De Brujin Graph for AAABBBBA\n\n\n\n\nWe say that a graph has a Eulerian walk if and only if each edge can be crossed exactly once.\nGenerally speaking, we can find a Eulerian walk in linear time - meaning that the mode edges we have in a graph, the tougher and longer it is to find an Eulerian walk (obviously).\n\n\n4.5.2 Making a De Brujin Graph for a Genome\nFirst things first, we need to assume that each K-mer doesn’t have any errors and is only sequenced once.\n\n\n\n\n\nSplitting the String a_long_long_long_time into 5-Mers and then 4-Mers\n\n\n\n\nIn the above example, we make a de Brujin graph with the string a_long_long_long_time using 5-mers. We then begin by splitting each 5-mer into two pairs of of \\(k - 1\\)-mers - in this case, 4-mers.\n\n\n\n\n\nFinal Results of the String a_long_long_long_time into 5-Mers and then 4-Mers\n\n\n\n\nIn the end, our graph looks something like the one shown above. Also note that the finished graph is Eulerian as it only has two semi-balanced nodes at best.\n\n\n4.5.3 Problems with De Brujin Graphs\n\n\n\n\n\nPossible Outcomes of an Ambiguous De Brujin Graph\n\n\n\n\nIf there is a repeat in a sequence, this can cause issues. Here, we see that there are two equally-likely outcomes.\n\n\n\n\n\nErrors Affecting the Outcome of a De Brujin Graph\n\n\n\n\nAs in, errors like the following can make the graph not appear good:\n\nGaps in coverage (i.e., missing k-mers)\nCoverage differences\nErrors and differences between chromosomes."
  },
  {
    "objectID": "chapters/week4.html#error-correction",
    "href": "chapters/week4.html#error-correction",
    "title": "4  De Novo Sequencing",
    "section": "4.6 Error Correction",
    "text": "4.6 Error Correction\n\n\n\n\n\nMapping Errors to a K-mer Histogram\n\n\n\n\nIf we look at the K-mer histogram, we see that frequent k-mers tend to turn into infrequent ones.\nSo, here’s what we can do…\n\n\n\n\n\nCorrecting Errors in a K-mer Histogram\n\n\n\n\nFor each k-mer in each read, we do the following:\n\nIf the k-mer count is less than some value, we look at the k-mer’s neighbors within some distance.\nIf the said neighbors have counts more than that “some value”, we replace the k-mer in question with the neighbor."
  },
  {
    "objectID": "chapters/week4.html#how-much-data-for-a-de-novo-assembly",
    "href": "chapters/week4.html#how-much-data-for-a-de-novo-assembly",
    "title": "4  De Novo Sequencing",
    "section": "4.7 How Much Data for a De Novo Assembly?",
    "text": "4.7 How Much Data for a De Novo Assembly?\n\n\n\n\n\nTheoretical Analyses of Gene Lengths for De Novo Assembly\n\n\n\n\nThe problem is that the entire assembly is probably longer than the repeats in the genome. We could sequence and also re-sequence a bacterial genome with read lengths of 20 to 30 base pairs or nucleotides.\nHowever, with longer genomes, significant proportions of the genome are uncovered."
  },
  {
    "objectID": "chapters/week5.html",
    "href": "chapters/week5.html",
    "title": "5  Annotation",
    "section": "",
    "text": "Genome evolution, which is how the genetic information in living things changes over time, happens in two main ways. These ways are like two different strategies that genes use to change and adapt.\nThe first way is called whole genome multiplication. Imagine if you had a favorite book, and you made a copy of the entire book. Then, you made another copy, so you had three identical books. In the same way, sometimes in genomes, the whole set of genes gets duplicated or even triplicated. This means there are extra copies of all the genes.\nThe second way is small scale duplication, and it’s a bit like making copies of individual chapters or pages from your favorite book. There are two types of small scale duplication: “segmental duplication” and “tandem duplication.”\nSegmental duplication is when certain sections of the genome, like chapters in a book, are copied more than once. This can lead to having extra copies of specific genes, which can be useful for evolution.\nTandem duplication is a little different. It’s like having two or more paragraphs on the same page that are exactly the same. In this case, genes are duplicated one right after the other in a row."
  },
  {
    "objectID": "chapters/week5.html#whole-genome-duplications",
    "href": "chapters/week5.html#whole-genome-duplications",
    "title": "5  Annotation",
    "section": "5.1 Whole Genome Duplications",
    "text": "5.1 Whole Genome Duplications\n\n\n\n\n\nIllustration of a Whole Genome Duplication Event\n\n\n\n\nIn the above example, we have a genome from two different organisms - one blue and one orange.\nIf the genomes of two organisms come together, this is called an autopolyploid. Otherwise, this is called an alloalyploid.\nWhen genome evolution happens through whole genome duplications, it’s like making an identical copy of the entire set of genes. Imagine you have a long list of items, and you make an exact duplicate of that list. Here’s what happens:\nRight after the duplication, the genes in both copies are in the same order, which scientists call “synteny.” It’s like having the same items in the same order on both lists.\nBut, as time goes by, some changes occur:\n\nFractionation\nThis is when the genome starts to change. Some genes get lost because they become redundant (like having two identical items on your list), and random mutations can also affect genes.\nGenome rearrangements\nThink of this as reshuffling the items on your list. The order of genes can change.\nSyntenic blocks\nEven after a long time, there are still some parts of the genome where a bunch of genes look very similar to another bunch. It’s like having sections of your list that are almost the same as sections in the duplicate list.\nDiploid form\nEventually, the genome organizes itself back into a diploid form. This means it goes back to having two sets of genes, like you have one original list and one duplicate list, but with some changes.\n\n\n5.1.1 Genome Duplication in Organisms\n\n5.1.1.1 Plants\n\n\n\n\n\nWhole Genome Duplication in Plants\n\n\n\n\nGenome duplications happen quite often in the evolution of plants. It’s like when you have a favorite plant and it suddenly makes extra copies of all its genetic instructions. Here are some examples:\nAncient Hexaploid Event in Eudicots: About 150 million years ago, a group of plants called Eudicots had a special event where their entire set of genes got duplicated not just once, but three times! It's like having three identical instruction manuals for a plant.\n\nGrape\nAfter that ancient event, some plants like grapes didn’t have any more big duplications. So, they just kept the three copies they had and didn’t make any new ones.\nPoplar\nOn the other hand, poplar, which is another type of plant, recently had a whole genome duplication event. This means it made a fresh copy of all its genes, so it now has two sets of instructions.\nArabidopsis\nArabidopsis, yet another type of plant, had two whole genome duplication events in its history. So, it’s like having three instruction manuals originally, then copying them twice more, for a total of six!\n\n\n\n5.1.1.2 Fish\n\n\n\n\n\nWhole Genome Duplication in Fish\n\n\n\n\nIn the world of minnows and carps, which belong to a group called Cyprininae, there are around 1,300 different species. Now, here’s something interesting: approximately 400 of these species are what we call “polyploid.”\nPolyploid is a special term that tells us these species have more than the usual set of genetic instructions. It’s like having extra copies of a recipe book. In the case of these minnows and carps, having extra genetic copies can sometimes be a helpful adaptation. It’s a bit like having extra tools in your toolbox—they can be useful for different situations.\n\n\n\n5.1.2 Comparing Genomes\n\n\n\n\n\nComparing Two Genomes Using a Dot Plot\n\n\n\n\nA dot plot is like a cool tool scientists use to compare different genomes, which are like the instruction manuals for living things. Here’s how it works:\nFirst, imagine you have a bunch of genes from two different organisms, and you want to see how similar they are. The dot plot helps you visualize this by showing dots where genes are similar.\nAt first, it looks a bit messy with lots of dots. But, at a basic level, it helps us find pairs of genes that are kind of like neighbors in the instruction manuals. These are called syntenic gene pairs, and they might be important for understanding how organisms are related.\nIf we want to get even more detailed, we can study these syntenic gene pairs more closely. It’s like zooming in on those neighbor genes to see exactly how they match up.\nOne way to find these syntenic blocks, which are groups of similar genes, is to use a special program called DAGchainer. It’s like a detective that helps us find these important blocks in the instruction manuals.\nDAGchainer uses a smart method called dynamic programming to do this. Think of it like a super organized way to solve puzzles and find important patterns in the genes. So, dot plots and programs like DAGchainer are tools scientists use to uncover the secrets hidden in genomes!\n\n\n5.1.3 Exploring Whole Genome Duplications with Synteny\n\n\n\n\n\nSynteny Plots\n\n\n\n\nImagine you have two sets of genes from different organisms, and you want to figure out when they had a big duplication event. Synteny is like a tool that helps us with this detective work.\nFirst, scientists do something called pairwise alignment, which is like comparing the two sets of genes to see which ones match up. These matching gene pairs are called syntenic gene pairs.\nNow, here’s the cool part: we can look at how many “synonymous substitutions” have happened in these gene pairs. Synonymous substitutions are like small changes in the genes that don’t really affect how the protein is made or its building blocks (amino acids).\nBy counting these mutations, it’s kind of like using a molecular clock. This clock tells us how much time has passed since the big gene duplication happened. Just like a clock helps us keep track of time, counting these mutations helps scientists figure out when the duplication event took place.\n\n\n5.1.4 Functional Biases on Gene Origins\n\n\n\n\n\nProf. Jarkko’s Graph\n\n\n\n\nWhen we talk about how genes work and where they come from, there are two main ways genes can be duplicated: Whole Genome Duplication (WGD) and Tandem Duplication. These two processes can affect how genes function.\nIn the case of Whole Genome Duplication (WGD), there’s something called the dosage-balance hypothesis. This means that genes that are really important and highly connected in the cell are usually kept around when gene duplication happens. Think of it like keeping the most important players on your sports team. These important genes often include things like transcription factors and regulators, which are like the coaches and referees of the cell.\nOn the other hand, with Tandem Duplication, it’s more about recent adaptations. Imagine if you have a group of friends, and you suddenly need to deal with a new challenge, like a surprise test. You might quickly form a study group with the friends who are best at that subject. Similarly, genes that are duplicated in tandem, one after the other, often include genes that help an organism cope with immediate changes in its environment. For example, if there’s a sudden threat from a pathogen, genes related to defense might get duplicated to help the organism adapt quickly.\n\n5.1.4.1 Why is this Important?\nAfter a special kind of gene duplication called Whole Genome Duplications (WGDs), the genes that stay around are usually super important. They’re like the VIPs of the cell—genes that help control things like when to grow, when to stop, and how to respond to signals. We call this idea the “dosage-balance hypothesis.”\nThe cool thing is that similar VIP genes can be found in almost all species, and they work in pretty similar ways. It’s like finding the same important tools in everyone’s toolbox. This makes it easier for scientists to find similar genes in different species, and we call these similar genes “orthologs.”\nNow, when genes are copied one after the other, like in Tandem Duplication, they often help an organism deal with changes in its environment. These are like the genes that help you adapt when something unexpected happens, like a sudden change in weather. These newly copied genes are very similar in their instructions.\nBut here’s where it gets tricky: these copied genes can be a bit different between individuals of the same species, and this can cause problems when scientists are trying to match up short pieces of genetic information (short reads) with the gene instructions.\n\n\n\n5.1.5 Implications for Genome Annotation\nFirst, think about the number of gene copies. It’s like saying that in some species, there might be more copies of a certain gene, while in others, there are fewer. It’s kind of like how some people have more toys than others. This variation in gene copies can make things a bit complicated.\nNow, when it comes to species, those that are more closely related, like siblings, tend to be more similar to each other in terms of their genes. But species that are very different, like distant cousins, might have genes that look quite different. It’s a bit like how you might look more like your brother or sister than a cousin you’ve never met.\nPolyploidy events are like times when a species had too many copies of its entire set of genes. Imagine if you suddenly had two toy chests filled with toys instead of one. It can be a bit tricky to figure out which toys are exactly the same in both chests, and this is kind of like the challenge scientists face when finding orthologs in species that have experienced polyploidy.\nLastly, with tandem duplications, it’s like having the same toy repeated in a row in your toy chest. When this happens with genes, it can be hard to predict because it looks like there’s just one type of toy in your chest, even though there are actually many copies of the same toy. So, for scientists trying to understand gene models, it can be a bit tricky to tell what’s going on."
  },
  {
    "objectID": "chapters/week5.html#quality-control-of-assembly",
    "href": "chapters/week5.html#quality-control-of-assembly",
    "title": "5  Annotation",
    "section": "5.2 Quality Control of Assembly",
    "text": "5.2 Quality Control of Assembly\n\n5.2.1 N50 Value\nWhen scientists are putting together the puzzle pieces of a genome, one of the most important things to check is how well those pieces fit together. This is called contiguity.\nContiguity is like looking at a jigsaw puzzle and making sure all the pieces are lined up nicely. You want to see how many separate pieces, called contigs or scaffolds, make up the genome.\n\n\n\n\n\nIllustration of the N50 Value\n\n\n\n\nNow, to tell how good the assembly is, we use a special number called the N50 value. This number tells us something really important: it shows the length where 50% of the genome assembly is made up of contigs or scaffolds longer than this length.\nThink of it like this: if you have a bunch of puzzle pieces, and you find the N50 value, it means that half of the puzzle pieces are at least that big. So, the higher the N50 value, the better the quality of the genome assembly because it means larger and more complete pieces are used to put together the genome.\n\n\n5.2.2 Conserved Single-Copy Genes\nWhen scientists are working on putting together a genome, one of the most crucial things they want to make sure of is that they capture all the important parts of the genes. Imagine if you were building a car, and you needed to make sure you had all the essential parts like the engine, wheels, and brakes. In genome assembly, those important parts are the genes.\nNow, here’s the tricky part: figuring out if you’ve got all the genes in their proper places can be hard without some extra help. It’s like trying to build a car without an instruction manual.\nBut scientists have a clever trick. They’ve looked at lots of different species and found a special group of genes that are found in nearly all genomes as single copies. This means there’s usually just one of each of these genes in the genome. It’s like finding common tools that are used in many different types of cars.\nThese single-copy genes are super important because they’re often the first ones to disappear if there are extra copies or if genes get shuffled around during evolution.\nTo help scientists check if they’ve got these essential genes in their genome assembly, they use software like CEGMA (which is a bit outdated now) and BUSCO. These programs act like detectives to see if all the crucial genes are present and in good shape, kind of like making sure you have all the essential car parts before you start driving.\n\n\n5.2.3 BUSCO\nImagine you have a big jigsaw puzzle, and you want to make sure you’re putting all the right pieces in the right places. In the world of genomes, those puzzle pieces are genes, and they need to be correctly identified and placed. This is where Benchmarking Universal Single-Copy Orthologs (i.e., BUSCO) comes in.\nBUSCO helps with genome annotation, which is like labeling and understanding the genes in a genome. It does this using a two-step approach:\nFirst, it uses something called tblastn to search for known single-copy protein sequences within the genome. Think of this as looking for specific shapes in your puzzle pieces that you know should be there.\nOnce it finds these matches, it uses them to teach a special tool called “Augustus” how to predict where other genes are in the genome. It’s like showing someone a few pieces of the puzzle so they can guess where the rest of the pieces should go.\nThen, Augustus starts predicting the genes and looks for matches to a set of genes that are known to be present as single copies in most genomes. These genes are kind of like the most important pieces of the puzzle.\nBUSCO gives a report that tells you the number of found full-length genes (genes that are complete and correct), duplicated full-length genes (genes that have extra copies), fractionated genes (genes that are split up), and missing genes (genes that are nowhere to be found).\nThe “Busco score” is a handy percentage that tells you how well your genome assembly is doing. If it’s over 95%, that’s really good and means you have a high-quality assembly. If it’s between 90-95%, that’s still good. But if it’s below 80%, it’s a sign that there might be issues with your genome assembly.\n\n5.2.3.1 Pros and Cons\nUsing BUSCO is like taking a quick test to check how well you’ve done a big job, like building a complex model. It’s become a standard method in genomics because it helps scientists figure out if they did a good job in understanding the genes of an organism quickly.\nNow, there are a few things to keep in mind when using BUSCO:\n\nNot the Whole Picture\nThe results from BUSCO might not tell you everything about the quality of the entire set of genes in the organism. It’s like if you looked at only a few parts of a car and assumed the whole car was in perfect shape.\nPredicting Easy Genes\nBUSCO focuses on finding genes that are considered “easy” to predict because they’re pretty much the same across many species. This means it might miss some of the more unique or hard-to-predict genes.\nReference Species\nBUSCO defines these “easy” genes based on a set of species used as a reference. However, not all organisms have the exact same genes, and in some cases, the genes might be so different that BUSCO can’t spot them.\nDuplicate Genes\nSometimes BUSCO might find extra copies of genes. This can happen because of problems with how the genome was put together (assembly problems) or because the organism naturally has extra copies due to recent genome duplications."
  },
  {
    "objectID": "chapters/week5.html#genome-annotation",
    "href": "chapters/week5.html#genome-annotation",
    "title": "5  Annotation",
    "section": "5.3 Genome Annotation",
    "text": "5.3 Genome Annotation\nLet’s break down three types of annotation tasks:\n\nGenome Annotation\nImagine you have a huge book with lots of words but no titles or chapters. Genome annotation is like giving titles to chapters in this book. Scientists try to figure out where the important genes are hiding in the DNA sequence of an organism’s genome. It’s like identifying the main characters in a story.\nStructural Annotation\nThis is about looking closer at the genes you’ve identified. It’s like studying the characters in a book and finding out if they have any special traits or abilities. In genetics, scientists try to spot specific patterns or “domains” in genes that are similar across different species. These domains are like superpowers for genes, and they help scientists understand what the genes do.\nFunctional Annotation\nOnce you know what the genes look like and what patterns they have, you want to figure out what they actually do. It’s like reading the book to learn about the characters’ roles. Scientists try to guess the function of a gene based on its patterns and shapes. They do this by finding genes in other species that are very similar in structure or sequence (like finding characters in other books that are a lot like the ones you already know). Then, they assume that these similar genes have similar functions. To be really sure, they might do experiments, like RNA sequencing or mutant tests, to check if their guess is right.\n\nSo, in a nutshell, genome annotation1 is like naming characters in a book (identifying genes), structural annotation is like discovering special traits of these characters (identifying patterns in genes), and functional annotation is like figuring out what these characters do in the story (identifying gene functions). It’s all about understanding the genetic story of an organism!\n\n5.3.1 Coding Regions\n\n\n\n\n\nIllustration of Introns and Exons\n\n\n\n\nWhen scientists study a genome, they’re like detectives trying to find important clues. They want to identify the functional parts of the genome, which are like the chapters and important details in a story. These functional parts include things like the promoter (which tells genes when to start), exons (which are the important coding parts of genes), and introns (which are like extra, non-coding sections within genes).\nNow, introns are like tricky puzzles in this genome story. They make the job of predicting or figuring out where genes start and stop a bit harder. It’s like trying to read a book with extra sentences that don’t make much sense. These introns can confuse scientists because they don’t contain the actual instructions for making proteins, so it’s like having extra pages in a recipe book that you don’t need."
  },
  {
    "objectID": "chapters/week5.html#repeat-analysis-and-making",
    "href": "chapters/week5.html#repeat-analysis-and-making",
    "title": "5  Annotation",
    "section": "5.4 Repeat Analysis and Making",
    "text": "5.4 Repeat Analysis and Making\n\n5.4.1 Repetitive and Transposable Elements\nIn genomes, there are parts that repeat themselves, like when a song chorus repeats several times. These repeating patterns in the genome come in different types:\n\nSimple Repeats\nThese are like when you say the same word over and over. They don’t have a lot of information.\nTransposable Elements\nThese are like special sequences that can move around in the genome. They come in two flavors: autonomous (like the main boss) and non-autonomous (like the helpers).\n\nTo find these repeating patterns, scientists use computer programs. These programs are like detectives with a set of tools. They follow a step-by-step process, sort of like how you might go through a recipe to cook something. These tools help them find the repeating patterns in the genome.\nOne of the most commonly used detective programs is called RepeatMasker. It’s like a superstar detective because it combines the powers of different tools to get the job done. Think of it as having multiple gadgets in a detective’s toolkit. RepeatMasker uses two de novo repeat-finding tools (RECON and RepeatScout) to identify new repeats, a tandem repeat finder to spot specific kinds of repeats, and a database called Repbase that holds information about known repeats from other species. It’s like using a reference book to help with the detective work.\nApart from RepeatMasker, there are some other detective software programs like PiRATE and Repet. They work in similar ways but might have their own unique tricks and features to find repeating patterns in the genome.\n\n\n5.4.2 Transcriptomic Evidence\nScientists use a special technique called RNA-sequencing to learn which genes are active in a cell or organism at a particular time. It’s like listening in on a conversation to see who’s talking.\nThis technique helps create something called a transcriptome, which is like a detailed list of all the genes that are “talking” or being used by the cell. It’s the most accurate way to know which genes are active.\nBut here’s the catch: just because you’re listening in on a conversation doesn’t mean you hear everyone talking. Similarly, not all genes will be “talking” or active at the same time, so the transcriptome will be incomplete. Some genes are like shy individuals who only speak up in certain situations.\nRNA-sequencing can also tell us about different types of genes. Some genes are only active in specific tissues (like heart genes in heart tissue), some follow a daily schedule (diurnal genes), and some are only used during certain stages of growth (developmental state-specific genes). It’s like finding out who talks only in the library, who talks only in the morning, and who talks only at a party!\nAnd sometimes, genes can have different versions, like how a story can be told in different ways. These are called splice variants, and they can be specific to certain tissues.\nScientists use RNA-sequencing data in two main ways:\n\nThey can match the “conversations” (reads) they hear to a known “script” (the genome) to figure out which genes are active. It’s like finding out who’s talking by checking a script.\nOr they can piece together a new “script” (de novo assembly) from the conversations and then figure out which genes are active. It’s like creating a script from scratch based on what people are saying.\n\n\n\n5.4.3 Prediction from Sequence (i.e., ab initio)\nTo learn patterns from genes, Bioinformaticians can turn to machine learning to make something called a hidden Markov model (i.e., HHM).\n\n\n\n\n\nLayout of a Hidden Markov Model\n\n\n\n\nA HHM is a kind of computer model that was first created back in the late 1970s. It wasn’t originally meant for genetics or biology, though. Instead, it was designed for something quite different: speech recognition.\nThe idea behind an HMM is to break down a process into two main parts: hidden states and observations. In the case of speech recognition, the hidden states represent different sounds or letters that make up spoken words, while the observations are like the actual sound signals.\nEach hidden state in the model is connected to a specific acoustic signal. So, when there’s a change in the hidden state, it’s like switching to a different letter or sound. When you put all these changes together, you get a sequence, or a path, of hidden states that make up a word.\nIn speech recognition, the goal is to figure out the most likely path of hidden states based on the sounds we hear. So, HMMs help computers understand spoken words by finding the best match between what they “hear” (the observations) and the most likely sequence of sounds (the hidden states). It’s like trying to guess the word someone is saying based on the sounds you hear.\n\n5.4.3.1 In Genetics?\nIn the world of genetics, scientists also use Hidden Markov Models (HMMs), but for a different purpose: understanding genes.\nJust like in speech recognition, HMMs for genes have hidden states and observations. In this case, the hidden states represent different parts of a gene, such as exons (the important coding sections), splice donors/acceptors (which are like gene punctuation marks), introns (non-coding parts within a gene), and intergenic regions (spaces between genes).\nThe observations, in this context, are the sequences of DNA letters (A, T, C, G) that make up the gene. It’s like looking at the genetic “code” to understand how genes are put together.\nA gene, in this model, is like a path that starts at the first exon and goes through all the hidden states, following the rules of the model.\n\n\n5.4.3.2 Why Use ab initio Predictions?\nFirst, it’s important to understand that not all genes are active or “expressed” in the samples being studied. Think of it like a library where not all the books are being read at the same time. RNA sequencing only tells us about the genes that are actively “reading” or expressing themselves.\nAnother reason is that some genes don’t follow the usual rules of gene splicing. It’s like having a few books in the library that are written in a different style, and these books might be missed by the RNA sequencing approach.\nLet’s take the example of birch, a type of tree. When scientists used RNAseq for birch, they found about 20,000 sequences (isotigs). However, to get a more complete picture, they still needed to predict around 10,000 genes computationally. This is because RNA sequencing doesn’t always capture all the genes.\nNow, when it comes to picking which gene prediction tools to use, there are a few top contenders in the field, like Augustus and BRAKER. But there are also many other software options available, making it a bit like choosing between different tools for a job.\nIn practice, scientists often use a combination of these tools. For birch, they tried out about 10 different gene predictors and ended up using the four that worked the best. This is because different predictors have different ways of modeling genes, so some might be better at detecting certain types of genes compared to others.\n\n\n\n5.4.4 Gene Models in Other Species\nOne of the key ways to make sure gene predictions are accurate is by looking at external evidence. Think of it like checking your work with a trusted source.\nOne of the most reliable sources of external evidence is RNA sequencing data. This data is like a gold standard because it tells us exactly which genes are active and how they’re structured. It’s a bit like having the answers to a test. Scientists can compare their gene predictions with RNA sequencing data to see if they match up.\nThere are two ways to use RNA sequencing data. One is called de novo transcriptome assembly, which is like putting together a puzzle without a picture on the box. It’s useful when you don’t have a complete genome to work with. But sometimes, it’s a bit like solving a puzzle with missing pieces, and it can be hard to tell similar genes apart.\nAnother good source of evidence is old collections of Expressed Sequence Tags (ESTs). These are like clues left behind by genes. Scientists can use these clues to confirm their gene predictions.\nIt’s also helpful to look at genes in well-studied or closely related species. It’s like asking someone who’s good at a subject for help. If these genes are similar to the ones you’re predicting, it adds confidence to your predictions.\nHowever, predicting genes in gene families that are right next to each other (tandem repeats) can still be a tricky puzzle. It’s like trying to tell identical twins apart. Sometimes, even with external evidence, it’s hard to be certain.\n\n5.4.4.1 Aligning Protein Evidence to Genome\nImagine you have a jigsaw puzzle, and you want to find where certain pieces fit. When scientists have pieces of evidence like proteins or transcripts and want to see where they match in a genome, it’s a bit like finding the right spot for puzzle pieces.\nOne way to do this is using a tool called tblastn. Think of it as a detective tool. What it does is take the genome and look at it in different ways, kind of like trying to read a book from different angles. It’s searching for matches to a protein or transcript.\nHowever, there’s a limitation with tblastn. It doesn’t take into account something important called splicing, which is like how sentences are rearranged in a book to make sense. So, tblastn might miss some of the edges or boundaries of where the protein or transcript matches the genome. It’s like finding parts of a sentence but not realizing where one sentence ends and another begins.\nTo get the whole picture, scientists use other tools like Exonerate, PASA, and GeMoMa. These are like detective tools with special glasses that help them see the splicing parts better. They pay attention to the spots where the sentences (or genes) are joined together with special signals called donor and acceptor sites.\nThese splicing-aware tools also do something clever. They look for regions in the genome where there’s a high match to the protein or transcript evidence and then join these regions together. It’s like finding pieces of a puzzle that fit really well and realizing they belong together."
  },
  {
    "objectID": "chapters/week5.html#combining-evidence",
    "href": "chapters/week5.html#combining-evidence",
    "title": "5  Annotation",
    "section": "5.5 Combining Evidence",
    "text": "5.5 Combining Evidence\nWhen scientists want to figure out what a gene does, they turn to a tool called Interproscan. It’s like using a detective kit with different tools to uncover the gene’s secrets. Interproscan does two important jobs at once. It’s a bit like looking at both the shape and function of a key to understand what it can unlock. For genes, it checks their structure and function.\nOne thing it checks is something called “conserved protein domains.” Think of these as like the building blocks or patterns that genes are made of. Interproscan compares these patterns to a big database that includes PFAM, protein superfamilies, and PANTHER.\nAnother tool in its kit is BLAST, which is like a gene family tree detective. It helps find genes that are similar to the one being studied. These similar genes can give clues about what the gene does. Interproscan also looks at metabolic pathways (like the chemical processes in a cell) using tools like KEGG and Metacyc. It’s like figuring out how ingredients are used in a recipe. It also predicts Gene Ontology (GO) categories, which are like labels that describe what a gene is involved in.\nTo assign a gene’s function, Interproscan uses something called the guilt-by-association principle. It’s like assuming that if someone is often seen with a group of people doing a particular activity, they’re likely involved in that activity too. In genes, if a gene is similar to others in a certain pathway or category, it’s probably involved in the same kind of job."
  },
  {
    "objectID": "chapters/week5.html#final-verification",
    "href": "chapters/week5.html#final-verification",
    "title": "5  Annotation",
    "section": "5.6 Final Verification",
    "text": "5.6 Final Verification\nProf. Jarkko lists a sample checklist for this bit - just to ensure that the genome in question is a good one:\n\nStart with the Gene Model\nBegin with the predicted gene model as your reference. It’s like having a blueprint for a building.\nCompare with RNAseq and EST Data\nCheck if the RNA sequencing (RNAseq) and EST data match the gene model. It’s similar to making sure the building looks like the blueprint.\nExamine Protein Matches in Other Species\nSee if proteins from related species match your gene. It’s like comparing your building to others in the neighborhood.\nBLAST the Protein Sequence\nUse a tool called BLAST to compare your gene’s protein sequence to a big database of genetic information. This helps you find similar genes in various species and might give hints about gene function.\nGather Good Hit Sequences\nCollect the sequences that closely match your gene, especially from well-studied model species. Think of it as getting advice from experts.\nMultiple Sequence Alignment\nLine up the protein sequences and see if they match well. It’s like checking if puzzle pieces fit together. Look out for mistakes like frame shifts, incorrect splicing, or missing start/stop signals.\nWatch Out for “Ns”\nIf you see “N” in the sequence, it means there’s missing information. It’s like having a blank spot on the blueprint.\nManual Adjustments\nIf needed, make manual adjustments to the gene model to improve accuracy. It’s like fine-tuning the building plans to make everything fit perfectly.\nExperimental Verification\nFinally, validate the gene model with experimental data. This involves using RNAseq and targeted experiments to confirm that the gene functions as predicted. It’s like testing the building to ensure it works as intended."
  }
]